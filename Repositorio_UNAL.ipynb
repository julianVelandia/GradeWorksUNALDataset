{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzjm02pFnE3M6B7x/vBtew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianVelandia/GradeWorksUNALDataset/blob/master/Repositorio_UNAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "!pip install python-certifi-win32\n",
        "!pip install certifi\n",
        "!pip install --upgrade certifi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz7HM2xolX6E",
        "outputId": "47c327f5-de7a-4c9c-d40c-72be451f4c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
            "Collecting python-certifi-win32\n",
            "  Downloading python_certifi_win32-1.6.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: wrapt>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from python-certifi-win32) (1.17.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-certifi-win32) (2024.12.14)\n",
            "Collecting setuptools-scm (from python-certifi-win32)\n",
            "  Downloading setuptools_scm-8.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (75.1.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (2.2.1)\n",
            "Downloading python_certifi_win32-1.6.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools-scm, python-certifi-win32\n",
            "Successfully installed python-certifi-win32-1.6.1 setuptools-scm-8.1.0\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.12.14)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy8xqTyRk507"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import pdfplumber\n",
        "import ssl\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from typing import List, Dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uri_in_json(uri):\n",
        "  file_name = 'uris.json'\n",
        "  if os.path.exists(file_name):\n",
        "      with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "          data = json.load(json_file)\n",
        "  else:\n",
        "      data = {\"uris\": {}}\n",
        "\n",
        "\n",
        "  data[\"uris\"][uri] = \"pending\"\n",
        "\n",
        "  with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "      json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "nfcUZk491E3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metadata_in_json(uri: str, data_dict: Dict[str, dict]):\n",
        "    file_name = 'dataset.json'\n",
        "\n",
        "    try:\n",
        "        try:\n",
        "            with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "                existing_data = json.load(json_file)\n",
        "        except (FileNotFoundError, json.JSONDecodeError):\n",
        "            existing_data = {}\n",
        "\n",
        "\n",
        "        existing_data[uri] = data_dict\n",
        "\n",
        "        with open(file_name, 'w',  encoding='utf-8') as json_file:\n",
        "            json.dump(existing_data, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {e}\")"
      ],
      "metadata": {
        "id": "bQLFTCLy1BZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uris_pdfs_and_metadata_from_repositorio_unal():\n",
        "  base_url = \"https://repositorio.unal.edu.co/handle/unal/5/recent-submissions?offset=\"\n",
        "  offset = 0\n",
        "  url_list = []\n",
        "  while offset <= 1900:\n",
        "      url = base_url + str(offset)\n",
        "      print('OFFSET: '+ str(offset))\n",
        "      offset += 20\n",
        "      try:\n",
        "        response = requests.get(url, verify=False)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        artifact_items = soup.find_all(class_=\"ds-artifact-item\")\n",
        "\n",
        "        for item in artifact_items:\n",
        "            item_wrapper = item.find('div', class_=\"item-wrapper row\")\n",
        "            if item_wrapper:\n",
        "                col_div = item_wrapper.find('div', class_=\"col-sm-3 hidden-xs\")\n",
        "\n",
        "                if col_div:\n",
        "                    thumbnail_div = col_div.find('div', class_=\"thumbnail artifact-preview\")\n",
        "                    if thumbnail_div:\n",
        "                        a_tag = thumbnail_div.find('a', class_=\"image-link\")\n",
        "\n",
        "                        if a_tag and 'href' in a_tag.attrs:\n",
        "                            item_page_url = a_tag['href']\n",
        "                            item_page_url = item_page_url.strip()\n",
        "                            item_page_url = 'https://repositorio.unal.edu.co' + item_page_url + '?show=full'\n",
        "                            item_page_response = requests.get(item_page_url, verify=False)\n",
        "                            item_page_soup = BeautifulSoup(item_page_response.content, 'html.parser')\n",
        "\n",
        "                            advisor_label = item_page_soup.find('td', class_='label-cell', string='dc.contributor.advisor')\n",
        "                            if advisor_label:\n",
        "                                advisor_row = advisor_label.find_parent('tr')\n",
        "                                advisor = str(advisor_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            author_label = item_page_soup.find('td', class_='label-cell', string='dc.contributor.author')\n",
        "                            if author_label:\n",
        "                                author_row = author_label.find_parent('tr')\n",
        "                                author = str(author_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            date_label = item_page_soup.find('td', class_='label-cell', string='dc.date.issued')\n",
        "                            if date_label:\n",
        "                                date_row = date_label.find_parent('tr')\n",
        "                                date = str(date_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "                            description_label = item_page_soup.find('td', class_='label-cell', string='dc.description.abstract')\n",
        "                            if description_label:\n",
        "                                description_row = description_label.find_parent('tr')\n",
        "                                description = str(description_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "                            title_label = item_page_soup.find('td', class_='label-cell', string='dc.title')\n",
        "                            if title_label:\n",
        "                                title_row = title_label.find_parent('tr')\n",
        "                                title = str(title_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            program_label = item_page_soup.find('td', class_='label-cell', string='dc.publisher.program')\n",
        "                            if program_label:\n",
        "                                program_row = program_label.find_parent('tr')\n",
        "                                program = str(program_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            faculty_label = item_page_soup.find('td', class_='label-cell', string='dc.publisher.faculty')\n",
        "                            if faculty_label:\n",
        "                                faculty_row = faculty_label.find_parent('tr')\n",
        "                                faculty = str(faculty_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            data_dict = {\n",
        "                                \"advisor\": advisor,\n",
        "                                \"author\": author,\n",
        "                                \"date\": date,\n",
        "                                \"description\": description,\n",
        "                                \"title\": title,\n",
        "                                \"program\": program,\n",
        "                                \"faculty\": faculty\n",
        "                            }\n",
        "                            url_element = item_page_soup.select_one('.thumbnail a')\n",
        "                            url_key =''\n",
        "                            if url_element:\n",
        "                                url_key = url_element.get('href')\n",
        "                            else:\n",
        "\n",
        "                              continue\n",
        "\n",
        "\n",
        "                            save_uri_in_json(url_key)\n",
        "                            save_metadata_in_json(url_key, data_dict)\n",
        "\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "        print('ERROR: '+url + str(e))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9o55Ko1QY-0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  if not os.path.exists('dataset.json') and not os.path.exists('uris.json'):\n",
        "      save_uris_pdfs_and_metadata_from_repositorio_unal()"
      ],
      "metadata": {
        "id": "lOBKVDtK1ZY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Se deberían tener 2 archivos:\n",
        "- Dataset.json\n",
        " - Lista de la información preliminar de la tesis (advisor, author, date, description, rtitle, program, faculty), con la uri como llave\n",
        "- uris.json\n",
        " - Lista de las uris (que son las keys de dataset) y un estado pending\n"
      ],
      "metadata": {
        "id": "taAtLk3xHRSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dataset.json\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"/bitstream/handle/unal/84578/1053812256.2023.pdf?sequence=2&isAllowed=y\": {\n",
        "        \"advisor\": \"Herrera León, Fernando Augusto\",\n",
        "        \"author\": \"Téllez González, Jonathan Salvador\",\n",
        "        \"date\": \"2023-08-11\",\n",
        "        \"description\": \"La finalidad del trabajo presente es mostrar ...\",\n",
        "        \"title\": \"Diseño de iluminación, control y embellecimiento de la cancha de Futbol del Estadio Alfonso López\",\n",
        "        \"program\": \"Bogotá - Ingeniería - Especialización en Iluminación Pública y Privada\",\n",
        "        \"faculty\": \"Facultad de Ingeniería\"\n",
        "}\n",
        "```\n",
        "\n",
        "- uris.json\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"uris\": {\n",
        "        \"/bitstream/handle/unal/84638/46386566.2023.pdf?sequence=2&isAllowed=y\": \"pending\",\n",
        "        \"/bitstream/handle/unal/84578/1053812256.2023.pdf?sequence=2&isAllowed=y\": \"pending\",\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "w_1XLmHRHVdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def from_url_to_txt(pdf_url):\n",
        "  try:\n",
        "    response = requests.get(pdf_url, verify=False)\n",
        "    response.raise_for_status()\n",
        "    pdf_stream = pdfplumber.open(BytesIO(response.content))\n",
        "    pdf_text = \"\"\n",
        "    for page in pdf_stream.pages:\n",
        "      page_text = page.extract_text()\n",
        "      pdf_text += page_text\n",
        "    pdf_stream.close()\n",
        "  except:\n",
        "    print('ERROR: '+pdf_url)\n",
        "  return pdf_text"
      ],
      "metadata": {
        "id": "oBP4RkLjkIke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_content_in_json(uri, raw_content):\n",
        "  file_name = 'raw_dataset.json'\n",
        "  if os.path.exists(file_name):\n",
        "      with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "          data = json.load(json_file)\n",
        "  else:\n",
        "      data = {\"raw\": []}\n",
        "\n",
        "\n",
        "  data[\"raw\"].append({\"uri\": uri, \"raw_content\": raw_content})\n",
        "\n",
        "  with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "      json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "qEug_XP_evtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_uri_state(uri, new_state):\n",
        "    file_name = 'uris.json'\n",
        "    if os.path.exists(file_name):\n",
        "        with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "            data = json.load(json_file)\n",
        "        if uri in data[\"uris\"]:\n",
        "            data[\"uris\"][uri] = new_state\n",
        "            with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "                json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "8qzoInre7J6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pending_uris():\n",
        "    file_name = 'uris.json'\n",
        "    pending_uris = []\n",
        "\n",
        "    if not os.path.exists(file_name):\n",
        "      uri_list = save_uris_pdfs_and_metadata_from_repositorio_unal()\n",
        "      return uri_list\n",
        "\n",
        "    with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        uris_dict = data.get(\"uris\", {})\n",
        "\n",
        "    for uri, state in uris_dict.items():\n",
        "        if state == \"pending\":\n",
        "            pending_uris.append(uri)\n",
        "\n",
        "    return pending_uris\n",
        "\n",
        "def get_error_uris():\n",
        "    file_name = 'uris.json'\n",
        "    error_uris = []\n",
        "\n",
        "    with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        uris_dict = data.get(\"uris\", {})\n",
        "\n",
        "    for uri, state in uris_dict.items():\n",
        "        if state == \"error\":\n",
        "            error_uris.append(uri)\n",
        "\n",
        "    return error_uris"
      ],
      "metadata": {
        "id": "PupQpAkQ7NhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uri_list = get_pending_uris()"
      ],
      "metadata": {
        "id": "mYYbxgwpK6M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(get_error_uris())"
      ],
      "metadata": {
        "id": "8z8aZVnGVfyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(uri_list)"
      ],
      "metadata": {
        "id": "9COR7l5b3tSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se extrae el contenido de cada PDF y se cambia el estado de 'pending' a 'complete'"
      ],
      "metadata": {
        "id": "uK7j-UjoZ-u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdfs_by_uri_and_update_state():\n",
        "  for uri in uri_list:\n",
        "    print('INICIA uri: ' + uri)\n",
        "    url = 'https://repositorio.unal.edu.co'+uri\n",
        "    try:\n",
        "      raw_content = from_url_to_txt(url)\n",
        "    except:\n",
        "      update_uri_state(uri, 'error')\n",
        "\n",
        "    if raw_content != '':\n",
        "      print('FINALIZA uri: ' + uri+ ' len: '+ str(len(raw_content)))\n",
        "      save_content_in_json(uri, raw_content)\n",
        "      update_uri_state(uri, 'complete')\n",
        "    else:\n",
        "      print('ERROR URI: '+ uri)\n",
        "      update_uri_state(uri, 'error')\n"
      ],
      "metadata": {
        "id": "lMOFvKRL3ugh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_pdfs_by_uri_and_update_state()"
      ],
      "metadata": {
        "id": "-Bf4mQtJ6oUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_raw_dataset():\n",
        "  file_name = 'raw_dataset.json'\n",
        "  raw_dataset = []\n",
        "  with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "HRlAyIRR8iXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_raw_data_to_dataset():\n",
        "  with open('dataset.json', 'r', encoding='utf-8') as dataset_file:\n",
        "    dataset = json.load(dataset_file)\n",
        "\n",
        "  with open('raw_dataset.json', 'r', encoding='utf-8') as raw_dataset_file:\n",
        "      raw_dataset = json.load(raw_dataset_file)\n",
        "\n",
        "  raw_content_mapping = {entry['uri']: entry['raw_content'] for entry in raw_dataset['raw']}\n",
        "\n",
        "  for uri, entry in dataset.items():\n",
        "      if uri in raw_content_mapping:\n",
        "          entry['raw_content'] = raw_content_mapping[uri]\n",
        "\n",
        "  with open('dataset.json', 'w', encoding='utf-8') as updated_dataset_file:\n",
        "      json.dump(dataset, updated_dataset_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "7bYXv2U9GSzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_raw_data_to_dataset()"
      ],
      "metadata": {
        "id": "BsAQXGqPi3m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se deberìan tener los datasets\n",
        "\n",
        "- dataset.json\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"/bitstream/handle/unal/84578/1053812256.2023.pdf?sequence=2&isAllowed=y\": {\n",
        "        \"advisor\": \"Herrera León, Fernando Augusto\",\n",
        "        \"author\": \"Téllez González, Jonathan Salvador\",\n",
        "        \"date\": \"2023-08-11\",\n",
        "        \"description\": \"La finalidad del trabajo presente es mostrar ...\",\n",
        "        \"title\": \"Diseño de iluminación, control y embellecimiento de la cancha de Futbol del Estadio Alfonso López\",\n",
        "        \"program\": \"Bogotá - Ingeniería - Especialización en Iluminación Pública y Privada\",\n",
        "        \"faculty\": \"Facultad de Ingeniería\",\n",
        "        \"raw_content\": \"Diseño de iluminación, control y\\nembellecimiento de la cancha de\\nFutbol...\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "- uris.json\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"uris\": {\n",
        "        \"/bitstream/handle/unal/84638/46386566.2023.pdf?sequence=2&isAllowed=y\": \"pending\",\n",
        "        \"/bitstream/handle/unal/84578/1053812256.2023.pdf?sequence=2&isAllowed=y\": \"pending\"\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "- raw_dataset.json\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"raw\": [\n",
        "        {\n",
        "            \"uri\": \"/bitstream/handle/unal/84578/1053812256.2023.pdf?sequence=2&isAllowed=y\",\n",
        "            \"raw_content\": \"Diseño de iluminación, control y\\nembellecimiento de la cancha de\\nFutbol...\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DulHOyG7JDDn"
      }
    }
  ]
}