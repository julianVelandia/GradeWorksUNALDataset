{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQd90ox31SiKNoUuNemo2J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "!pip install python-certifi-win32\n",
        "!pip install certifi\n",
        "!pip install --upgrade certifi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz7HM2xolX6E",
        "outputId": "5829f230-747d-4e5e-966a-6721dd63d372"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.19.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Requirement already satisfied: python-certifi-win32 in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: wrapt>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from python-certifi-win32) (1.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-certifi-win32) (2023.7.22)\n",
            "Requirement already satisfied: setuptools-scm in /usr/local/lib/python3.10/dist-packages (from python-certifi-win32) (7.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (4.7.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->python-certifi-win32) (2.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2023.7.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fy8xqTyRk507"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "import pdfplumber\n",
        "import ssl\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from typing import List, Dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uri_in_json(uri):\n",
        "  file_name = 'uris.json'\n",
        "  if os.path.exists(file_name):\n",
        "      with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "          data = json.load(json_file)\n",
        "  else:\n",
        "      data = {\"uris\": {}}\n",
        "\n",
        "\n",
        "  data[\"uris\"][uri] = \"pending\"\n",
        "\n",
        "  with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "      json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "nfcUZk491E3T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metadata_in_json(uri: str, data_dict: Dict[str, dict]):\n",
        "    file_name = 'dataset.json'\n",
        "\n",
        "    try:\n",
        "        try:\n",
        "            with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "                existing_data = json.load(json_file)\n",
        "        except (FileNotFoundError, json.JSONDecodeError):\n",
        "            existing_data = {}\n",
        "\n",
        "\n",
        "        existing_data[uri] = data_dict\n",
        "\n",
        "        with open(file_name, 'w',  encoding='utf-8') as json_file:\n",
        "            json.dump(existing_data, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {e}\")"
      ],
      "metadata": {
        "id": "bQLFTCLy1BZc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_uris_pdfs_and_metadata_from_repositorio_unal():\n",
        "  base_url = \"https://repositorio.unal.edu.co/handle/unal/5/recent-submissions?offset=\"\n",
        "  offset = 0\n",
        "  url_list = []\n",
        "  while offset <= 1900:\n",
        "      url = base_url + str(offset)\n",
        "      print('OFFSET: '+ str(offset))\n",
        "      offset += 20\n",
        "      try:\n",
        "        response = requests.get(url, verify=False)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        artifact_items = soup.find_all(class_=\"ds-artifact-item\")\n",
        "\n",
        "        for item in artifact_items:\n",
        "            item_wrapper = item.find('div', class_=\"item-wrapper row\")\n",
        "            if item_wrapper:\n",
        "                col_div = item_wrapper.find('div', class_=\"col-sm-3 hidden-xs\")\n",
        "\n",
        "                if col_div:\n",
        "                    thumbnail_div = col_div.find('div', class_=\"thumbnail artifact-preview\")\n",
        "                    if thumbnail_div:\n",
        "                        a_tag = thumbnail_div.find('a', class_=\"image-link\")\n",
        "\n",
        "                        if a_tag and 'href' in a_tag.attrs:\n",
        "                            item_page_url = a_tag['href']\n",
        "                            item_page_url = item_page_url.strip()\n",
        "                            item_page_url = 'https://repositorio.unal.edu.co' + item_page_url + '?show=full'\n",
        "                            item_page_response = requests.get(item_page_url, verify=False)\n",
        "                            item_page_soup = BeautifulSoup(item_page_response.content, 'html.parser')\n",
        "\n",
        "                            advisor_label = item_page_soup.find('td', class_='label-cell', string='dc.contributor.advisor')\n",
        "                            if advisor_label:\n",
        "                                advisor_row = advisor_label.find_parent('tr')\n",
        "                                advisor = str(advisor_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            author_label = item_page_soup.find('td', class_='label-cell', string='dc.contributor.author')\n",
        "                            if author_label:\n",
        "                                author_row = author_label.find_parent('tr')\n",
        "                                author = str(author_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            date_label = item_page_soup.find('td', class_='label-cell', string='dc.date.issued')\n",
        "                            if date_label:\n",
        "                                date_row = date_label.find_parent('tr')\n",
        "                                date = str(date_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "                            description_label = item_page_soup.find('td', class_='label-cell', string='dc.description.abstract')\n",
        "                            if description_label:\n",
        "                                description_row = description_label.find_parent('tr')\n",
        "                                description = str(description_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "                            title_label = item_page_soup.find('td', class_='label-cell', string='dc.title')\n",
        "                            if title_label:\n",
        "                                title_row = title_label.find_parent('tr')\n",
        "                                title = str(title_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            program_label = item_page_soup.find('td', class_='label-cell', string='dc.publisher.program')\n",
        "                            if program_label:\n",
        "                                program_row = program_label.find_parent('tr')\n",
        "                                program = str(program_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            faculty_label = item_page_soup.find('td', class_='label-cell', string='dc.publisher.faculty')\n",
        "                            if faculty_label:\n",
        "                                faculty_row = faculty_label.find_parent('tr')\n",
        "                                faculty = str(faculty_row.find_all('td', class_='word-break')[0]).replace('<td class=\"word-break\">', '').replace('</td>','')\n",
        "\n",
        "\n",
        "                            data_dict = {\n",
        "                                \"advisor\": advisor,\n",
        "                                \"author\": author,\n",
        "                                \"date\": date,\n",
        "                                \"description\": description,\n",
        "                                \"title\": title,\n",
        "                                \"program\": program,\n",
        "                                \"faculty\": faculty\n",
        "                            }\n",
        "                            url_element = item_page_soup.select_one('.thumbnail a')\n",
        "                            url =''\n",
        "                            if url_element:\n",
        "                                url = url_element.get('href')\n",
        "                            else:\n",
        "                              continue\n",
        "\n",
        "\n",
        "                            save_uri_in_json(url)\n",
        "                            save_metadata_in_json(url, data_dict)\n",
        "                            break\n",
        "            break\n",
        "\n",
        "      except:\n",
        "        print('ERROR: '+item_page_url)\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "id": "9o55Ko1QY-0h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_uris_pdfs_and_metadata_from_repositorio_unal()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOBKVDtK1ZY7",
        "outputId": "04be1a61-43b4-4e92-bc17-540dec992206"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OFFSET: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'repositorio.unal.edu.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'repositorio.unal.edu.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def from_url_to_txt(pdf_url):\n",
        "  try:\n",
        "    response = requests.get(pdf_url, verify=False)\n",
        "    response.raise_for_status()\n",
        "    pdf_stream = pdfplumber.open(BytesIO(response.content))\n",
        "    pdf_text = \"\"\n",
        "    for page in pdf_stream.pages:\n",
        "      page_text = page.extract_text()\n",
        "      pdf_text += page_text\n",
        "    pdf_stream.close()\n",
        "  except:\n",
        "    print('ERROR: '+pdf_url)\n",
        "  return pdf_text"
      ],
      "metadata": {
        "id": "oBP4RkLjkIke"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_content_in_json(uri, raw_content):\n",
        "  file_name = 'raw_dataset.json'\n",
        "  if os.path.exists(file_name):\n",
        "      with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "          data = json.load(json_file)\n",
        "  else:\n",
        "      data = {\"raw\": []}\n",
        "\n",
        "\n",
        "  data[\"raw\"].append({\"uri\": uri, \"raw_content\": raw_content})\n",
        "\n",
        "  with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "      json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "qEug_XP_evtj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_uri_state(uri, new_state):\n",
        "    file_name = 'uris.json'\n",
        "    if os.path.exists(file_name):\n",
        "        with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "            data = json.load(json_file)\n",
        "        if uri in data[\"uris\"]:\n",
        "            data[\"uris\"][uri] = new_state\n",
        "            with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "                json.dump(data, json_file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "8qzoInre7J6c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pending_uris():\n",
        "    file_name = 'uris.json'\n",
        "    pending_uris = []\n",
        "\n",
        "    if not os.path.exists(file_name):\n",
        "      uri_list = save_uris_pdfs_and_metadata_from_repositorio_unal()\n",
        "      return uri_list\n",
        "\n",
        "    with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        uris_dict = data.get(\"uris\", {})\n",
        "\n",
        "    for uri, state in uris_dict.items():\n",
        "        if state == \"pending\":\n",
        "            pending_uris.append(uri)\n",
        "\n",
        "    return pending_uris\n",
        "\n",
        "def get_error_uris():\n",
        "    file_name = 'uris.json'\n",
        "    error_uris = []\n",
        "\n",
        "    with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        uris_dict = data.get(\"uris\", {})\n",
        "\n",
        "    for uri, state in uris_dict.items():\n",
        "        if state == \"error\":\n",
        "            error_uris.append(uri)\n",
        "\n",
        "    return error_uris"
      ],
      "metadata": {
        "id": "PupQpAkQ7NhQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARGAR ARCHIVOS uris.json y raw_dataset.json SI EXISTEN\n"
      ],
      "metadata": {
        "id": "Zx9jAiN8K0Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri_list = get_pending_uris()"
      ],
      "metadata": {
        "id": "mYYbxgwpK6M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(get_error_uris())"
      ],
      "metadata": {
        "id": "8z8aZVnGVfyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5c695b-9883-4331-8b3d-9250885df4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(uri_list)"
      ],
      "metadata": {
        "id": "9COR7l5b3tSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba9a6ec-283c-44e4-fb03-01b85fb13c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se extrae el contenido de cada PDF y se cambia el estado de 'pending' a 'complete'"
      ],
      "metadata": {
        "id": "uK7j-UjoZ-u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for uri in uri_list:\n",
        "  print('INICIA uri: ' + uri)\n",
        "  url = 'https://repositorio.unal.edu.co'+uri\n",
        "  try:\n",
        "    raw_content = from_url_to_txt(url)\n",
        "  except:\n",
        "    update_uri_state(uri, 'error')\n",
        "\n",
        "  if raw_content != '':\n",
        "    print('FINALIZA uri: ' + uri+ ' len: '+ str(len(raw_content)))\n",
        "    save_content_in_json(uri, raw_content)\n",
        "    update_uri_state(uri, 'complete')\n",
        "  else:\n",
        "    print('ERROR URI: '+ uri)\n",
        "    update_uri_state(uri, 'error')\n"
      ],
      "metadata": {
        "id": "lMOFvKRL3ugh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_raw_dataset():\n",
        "  file_name = 'raw_dataset.json'\n",
        "  raw_dataset = []\n",
        "  with open(file_name, 'r', encoding='utf-8') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "HRlAyIRR8iXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_content(text, index):\n",
        "    content_started = False\n",
        "    content = []\n",
        "\n",
        "    lines = text.split(\"\\n\")\n",
        "    i = 0\n",
        "    j =0\n",
        "    for line in lines:\n",
        "      if content_started:\n",
        "            j+=1\n",
        "            if j==100:\n",
        "              print('ERROR NO END')\n",
        "              return ['ERROR']\n",
        "\n",
        "            if \"referencias\" in line.strip().lower() or \"bibliograf\" in line.strip().lower():\n",
        "              break\n",
        "            if re.match(r'^\\d+\\.\\d+', line.lstrip()):\n",
        "              print('salto: '+line.lstrip())\n",
        "              continue\n",
        "            line= line.strip().lower().replace('.', '').lstrip('0123456789').rstrip('0123456789')\n",
        "            line = re.sub(r'\\b(?:i|ii|iii|iv|v|vi|vii|viii|ix|x)+\\b', '', line, flags=re.IGNORECASE).lstrip().rstrip()\n",
        "\n",
        "            if line != '' and 'anexo' not in line:\n",
        "              content.append(line)\n",
        "      i+=1\n",
        "      if i == 1000 and not content_started:\n",
        "        print('ERROR NOT FOUND')\n",
        "        return ['ERROR']\n",
        "\n",
        "      if  line.strip().lower().lstrip().rstrip().lstrip('0123456789').endswith(\"contenido\") or line.strip().lower().lstrip().rstrip().lstrip('0123456789').endswith('índice'):\n",
        "          content_started = True\n",
        "\n",
        "\n",
        "    content.append(str(index)+ '-------------------------------------------------------')\n",
        "    return content"
      ],
      "metadata": {
        "id": "JS7O47Mk6JUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = get_list_raw_dataset()['raw']\n"
      ],
      "metadata": {
        "id": "12vPB0pN8UiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_content(raw_data[0]['raw_content']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur3m30At-5ay",
        "outputId": "ddb964d9-9370-4608-fcf8-e02c3af05b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['contenido', 'pág', 'resumen', 'lista de figuras', 'lista de tablas', 'introducción', 'estadio alfonso lópez', 'historia', 'ubicación', 'estructura', 'criterios de diseño', 'normas aplicables', 'cancha de futbol', 'iluminación de emergencia', 'ubicación de luminarias', 'diseño de iluminación', 'características de las luminarias', 'factor de mantenimiento', 'resultados de diseño', 'disposición de luminarias', 'iluminación arquitectónica', 'control de iluminación', 'controlador mediante software', 'equipo transmisor', 'equipo receptor', 'conexión luminarias', 'análisis financiero', 'conclusiones y recomendaciones']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = []\n",
        "no_content_uris = []\n",
        "i=0\n",
        "c = ['ERROR']\n",
        "for raw in raw_data:\n",
        "  i+=1\n",
        "  if i == 100:\n",
        "    break\n",
        "  c = extract_content(raw['raw_content'], i)\n",
        "  if c[0] == 'ERROR':\n",
        "    no_content_uris.append(raw['uri'])\n",
        "  else:\n",
        "    for item in c:\n",
        "      if item not in content:\n",
        "        content.append(item)"
      ],
      "metadata": {
        "id": "LPKKi3hgBtDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content"
      ],
      "metadata": {
        "id": "lparsPRWZaC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_content_uris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXcKr9OEbXIu",
        "outputId": "ca5f74fe-3c0a-4e90-f663-1da4677e3b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/bitstream/handle/unal/84368/1116912174.2023.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/84121/Proyecto%20de%20grado%20EDDP%20Sacha%20Inchi.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83939/1136883450.2023.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83548/1037601498.2023.pdf?sequence=4&isAllowed=y',\n",
              " '/bitstream/handle/unal/83545/1107076883.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83297/1023890031.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83208/1073604762.2023.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83178/1032419191.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83159/1052382665.2023.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83105/80829001-2023.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83083/1136884823.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/83002/87069558.2022%20.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/82971/1018463545.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/82907/1016034724.2022.pdf?sequence=2&isAllowed=y',\n",
              " '/bitstream/handle/unal/82885/1018474999.2022.pdf.pdf?sequence=2&isAllowed=y']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    }
  ]
}